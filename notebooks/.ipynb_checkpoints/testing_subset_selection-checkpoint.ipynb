{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pycss.utils import *\n",
    "from pycss.subset_selection import *\n",
    "from scipy import stats\n",
    "from notebook_utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_submatrix(mat, ind1, ind2, mat_replace):\n",
    "    for i, index in enumerate(ind1):\n",
    "        mat[index, ind2] = mat_replace[i, :]\n",
    "    return mat\n",
    "\n",
    "def compute_Sigma_MLE(Sigma, S, noise='sph'):\n",
    "    p = Sigma.shape[0]\n",
    "    k = len(S)\n",
    "    S = np.sort(S)\n",
    "    S_comp = complement(p, S)\n",
    "    Sigma_R = regress_off(Sigma, S) \n",
    "    D_ = np.diag(Sigma_R)[S_comp]\n",
    "    if noise == 'sph':\n",
    "        D = np.ones(p - k) * np.mean(D_)\n",
    "    if noise == 'diag':\n",
    "        D = D_.copy()\n",
    "    Sigma_MLE = np.zeros((p, p))\n",
    "    Sigma_MLE = replace_submatrix(Sigma_MLE, S, S, Sigma[S, :][:, S])\n",
    "    Sigma_MLE = replace_submatrix(Sigma_MLE, S, S_comp,  Sigma[S, :][:, S_comp])\n",
    "    Sigma_MLE = replace_submatrix(Sigma_MLE, S_comp, S, Sigma[S_comp, :][:, S])\n",
    "    Sigma_MLE = replace_submatrix(Sigma_MLE, S_comp, S_comp, Sigma[S_comp, :][:, S] @  np.linalg.inv(Sigma[S, :][:, S]) @ Sigma[S, :][:, S_comp] + np.diag(D))\n",
    "    return Sigma_MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate factor model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 50\n",
    "n= 2000\n",
    "k= 15\n",
    "\n",
    "W = np.random.multivariate_normal(np.zeros(k), cov=np.eye(k), size=p)\n",
    "D = np.square(np.random.normal(0, 1, p))\n",
    "Sigma = W @ W.T\n",
    "np.fill_diagonal(Sigma, np.diag(Sigma) + D)\n",
    "Sigma = standardize_cov(Sigma)\n",
    "X = np.random.multivariate_normal(np.zeros(p), cov= Sigma, size=n)\n",
    "mu_hat, Sigma_hat = get_moments(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Greedy CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, p):\n",
    "    S, Sigma_R, errors = greedy_subset_selection(Sigma_hat, k, css_objective, flag_colinearity=False, tol=TOL)\n",
    "    if len(errors) > 0:\n",
    "        print('Colinearity errors at ' + str(k) + ': ', errors)\n",
    "    S_removed = S[:(k - 1)]\n",
    "    S_removed_comp = complement(p, S_removed)\n",
    "    temp_objectives = []\n",
    "    for t in S_removed_comp:\n",
    "        S_added= np.concatenate([S_removed, np.array([t])]).astype(int)\n",
    "        temp_objectives.append(np.mean(np.diag(regress_off(Sigma_hat, S_added, tol=TOL))))\n",
    "    if S_removed_comp[np.argmin(temp_objectives)] != S[k-1]:\n",
    "        print('Mistake at ', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Swapping CSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(1, 15):\n",
    "    S, Sigma_R, S_init, converged, errors = swapping_subset_selection(Sigma_hat, k, css_objective, flag_colinearity=False, tol=TOL)\n",
    "    if len(errors) > 0:\n",
    "        print('Colinearity errors at ' + str(k) + ': ', errors)\n",
    "    if not converged:\n",
    "        print(str(k) + ' did not converge')\n",
    "        continue \n",
    "    for i in range(len(S)):\n",
    "        chosen = S[i]\n",
    "        S_temp = np.delete(S, i)\n",
    "        S_temp_comp = complement(p, S_temp)\n",
    "        temp_objectives = []\n",
    "    for t in S_temp_comp:\n",
    "        S_added= np.concatenate([S_temp, np.array([t])]).astype(int)\n",
    "        temp_objectives.append(np.mean(np.diag(regress_off(Sigma_hat, S_added, tol=TOL))))\n",
    "    if S_temp_comp[np.argmin(temp_objectives)] != chosen:\n",
    "        print('Mistake at ', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Greedy PCSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 'sph'\n",
    "\n",
    "for k in range(1, p-1):\n",
    "    if noise == 'sph':\n",
    "        S, Sigma_R, errors = greedy_subset_selection(Sigma_hat, k, sph_pcss_objective, flag_colinearity=True, tol=TOL)\n",
    "    if noise == 'diag':\n",
    "        S, Sigma_R, errors = greedy_subset_selection(Sigma_hat, k, diag_pcss_objective, flag_colinearity=True, tol=TOL)\n",
    "    if len(errors) > 0:\n",
    "        print('Colinearity errors at ' + str(k) + ': ', errors)\n",
    "    S_removed = S[:(k - 1)]\n",
    "    S_removed_comp = complement(p, S_removed)\n",
    "    temp_objectives = []\n",
    "    for t in S_removed_comp:\n",
    "        S_added = np.concatenate([S_removed, np.array([t])]).astype(int)\n",
    "        Sigma_MLE_temp = compute_Sigma_MLE(Sigma_hat, S=S_added, noise=noise)\n",
    "        temp_objectives.append(-1 * np.mean(stats.multivariate_normal(mean=mu_hat, cov=Sigma_MLE_temp).logpdf(X)))\n",
    "    if S_removed_comp[np.argmin(temp_objectives)] != S[k-1]:\n",
    "        print('Mistake at ', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Swapping PCSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 'sph'\n",
    "\n",
    "for k in range(1, 15):\n",
    "    if noise == 'sph':\n",
    "        S, Sigma_R, S_init, converged, errors = swapping_subset_selection(Sigma_hat, k, sph_pcss_objective, flag_colinearity=True, tol=TOL)\n",
    "    if noise == 'diag':\n",
    "        S, Sigma_R, S_init, converged, errors = swapping_subset_selection(Sigma_hat, k, diag_pcss_objective, flag_colinearity=True, tol=TOL)\n",
    "  \n",
    "    if len(errors) > 0:\n",
    "        print('Colinearity errors at ' + str(k) + ': ', errors)\n",
    "\n",
    "    if not converged:\n",
    "        print(str(k) + ' did not converge')\n",
    "        continue \n",
    "\n",
    "    for i in range(len(S)):\n",
    "        chosen = S[i]\n",
    "        S_temp = np.delete(S, i)\n",
    "        S_temp_comp = complement(p, S_temp)\n",
    "        temp_objectives = []\n",
    "        for t in S_temp_comp:\n",
    "            S_added= np.concatenate([S_temp, np.array([t])]).astype(int)\n",
    "            Sigma_MLE_temp = compute_Sigma_MLE(Sigma_hat, S=S_added, noise=noise)\n",
    "            temp_objectives.append(-1 * np.mean(stats.multivariate_normal(mean=mu_hat, cov=Sigma_MLE_temp).logpdf(X)))\n",
    "        if S_temp_comp[np.argmin(temp_objectives)] != chosen:\n",
    "            print('Mistake at ', k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e8e6b0daa73b41664b185076c529236510f1ca31ed4d2fa545660d2cd784378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
