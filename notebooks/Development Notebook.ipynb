{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e837d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pycss.utils import *\n",
    "from pycss.subset_selection import *\n",
    "from pycss.CSS import *\n",
    "import warnings\n",
    "import tqdm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a01a881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.22044605e-17, -8.32667268e-18, -2.49800181e-17,  3.33066907e-17,\n",
       "       -3.33066907e-17,  2.22044605e-17,  1.52655666e-17, -1.11022302e-17,\n",
       "       -2.22044605e-17,  4.44089210e-17,  2.22044605e-17,  6.93889390e-18,\n",
       "       -7.77156117e-17,  3.33066907e-17, -5.55111512e-18, -4.99600361e-17,\n",
       "        2.77555756e-17, -2.22044605e-17, -2.22044605e-17,  2.22044605e-17])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.normal(0, 1, (p, p))\n",
    "X -= np.mean(X, axis=0)\n",
    "np.mean(X, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f0c6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[19]\n",
      "[ 0 16 17 18]\n",
      "155.00000000000003\n",
      "[ 0.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16.  0.  0.\n",
      "  0. 20.]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "css =CSS()\n",
    "css.select_subset_from_data(X, center=False, k=4, method='exhaustive', standardize=False, exclude=np.array([19]), include=np.array([0]), show_progress=False)\n",
    "print(css.include)\n",
    "print(css.exclude)\n",
    "print(css.S)\n",
    "print(np.trace(css.Sigma_R))\n",
    "print(np.diag(css.Sigma_R))\n",
    "print(len(css.S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e32be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -6.66133815e-16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(css.Sigma_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d41c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 11])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23b3b6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.arange(p-k), np.zeros(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b3268aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Include must be a numpy array of integers from 0 to p-1.\n",
      "Exclude must be a numpy array of integers from 0 to p-1.\n"
     ]
    }
   ],
   "source": [
    "check_greedy_css_inputs(np.diag(np.arange(10)), \n",
    "                        k=3, \n",
    "                        cutoffs=None, \n",
    "                        include=np.array([]), \n",
    "                        exclude = np.array([]), \n",
    "                        tol=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a12cb38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exhaustive_css(Sigma, \n",
    "                   k, \n",
    "                   include=np.array([]),\n",
    "                   exclude=np.array([]),\n",
    "                   show_progress=True):\n",
    "    p = Sigma.shape[0]\n",
    "\n",
    "    best_S = None\n",
    "    best_Sigma_R = None\n",
    "    best_obj_val = np.inf \n",
    "\n",
    "    options = np.array([idx for idx in np.arange(p) if idx not in np.concatenate([include, exclude])])\n",
    "    to_add = k - len(include)\n",
    "    S = np.concatenate([include, -1*np.ones(to_add)]).astype(int)\n",
    "\n",
    "    if show_progress:\n",
    "        print(\"Iterating over \" + str(math.comb(len(options), to_add)) + \" different subsets...\")\n",
    "        iterator = tqdm.tqdm(itertools.combinations(options, to_add))\n",
    "    else:\n",
    "        iterator = itertools.combinations(options, to_add)\n",
    "\n",
    "    for  remaining in iterator:\n",
    "        S[len(include):] = np.array(remaining).astype(int)\n",
    "        Sigma_R = regress_off(Sigma, S)\n",
    "        obj_val = np.trace(Sigma_R)\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val\n",
    "            best_S = S\n",
    "            best_Sigma_R = Sigma_R\n",
    "    \n",
    "    return best_S, best_Sigma_R \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3840495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  4, 11, 12, 14, 15, 17, 18, 19, 21]),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  5.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  6.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  8.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  9.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         13.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0., 16.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0., 20.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exhaustive_css(np.diag(np.arange(22)), k=10, include=np.array([0,4]), exclude=np.array([20, 13, 16]), show_progress=False)\n",
    "\n",
    "\n",
    "#MAKE SURE S_INIT AND INCLUDE EXCLUDE ARE INTEGER TYPE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "a41433fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOL =1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "a18f68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def css_score(Sigma_R, tol=TOL):\n",
    "    diag = np.diag(Sigma_R)\n",
    "    return -1 * np.divide(np.sum(np.square(Sigma_R), axis=1), diag, out=np.zeros_like(diag, dtype=float), where=(diag > tol))\n",
    "\n",
    "def check_greedy_css_inputs(Sigma, k, cutoffs, include, exclude, tol):\n",
    "    n, p = Sigma.shape \n",
    "\n",
    "    if not n == p:\n",
    "        raise ValueError(\"Sigma must be a square matrix.\")\n",
    "  \n",
    "    if k is None and cutoffs is None:\n",
    "        raise ValueError(\"One of k or cutoff must not be None.\")\n",
    "  \n",
    "    if k is not None and cutoffs is not None:\n",
    "        raise ValueError(\"Only one of k or cutoff can be None.\")\n",
    "\n",
    "    if cutoffs is not None:\n",
    "        if (isinstance(cutoffs, (list, np.ndarray)) and not len(cutoffs) == p) or not isinstance(cutoffs, (int, np.integer, float)):\n",
    "            raise ValueError(\"Cutoffs must be a single value or length p.\")\n",
    "\n",
    "    if k is not None and not isinstance(k, (int, np.integer)):\n",
    "        raise ValueError(\"k must be an integer.\")\n",
    "    if k is not None and (k <= 0 or k > p):\n",
    "        raise ValueError(\"k must be > 0 and <= p.\")\n",
    "\n",
    "    set_include = set(include)\n",
    "    set_exclude = set(exclude)\n",
    "    if not set_include.issubset(np.arange(p)):\n",
    "        raise ValueError(\"Exclude must be a subset of the available indices.\")\n",
    "    if not set_exclude.issubset(np.arange(p)):\n",
    "        raise ValueError(\"Include must be a subset of the available indices.\")\n",
    "    if len(set_exclude.intersection(set_include)) > 0:\n",
    "        raise ValueError(\"Include and exclude must be disjoint.\")\n",
    "        \n",
    "    if len(exclude) == p:\n",
    "        raise ValueError(\"Cannot exclude everything.\")\n",
    "    if k is not None and len(include) > k:\n",
    "        raise ValueError(\"Cannot include more than k.\")\n",
    "    if k is not None and len(exclude) > p - k:\n",
    "        raise ValueError(\"Cannot exclude more than p-k.\")\n",
    "\n",
    "\n",
    "    if not isinstance(tol, float):\n",
    "        raise ValueError(\"tol must be a float.\")\n",
    "\n",
    "    return\n",
    "\n",
    "def greedy_css(Sigma,\n",
    "               k=None,\n",
    "               cutoffs=None,\n",
    "               include=np.array([]),\n",
    "               exclude=np.array([]),\n",
    "               tol=TOL,\n",
    "               ):\n",
    "\n",
    "    check_greedy_css_inputs(Sigma, k, cutoffs, include, exclude, tol)\n",
    "\n",
    "    Sigma_R = Sigma.copy()\n",
    "    p = Sigma.shape[0]\n",
    "    S = -1 * np.ones(p).astype(int)\n",
    "\n",
    "    if isinstance(cutoffs, (int, np.integer, float)):\n",
    "        cutoffs = cutoffs * np.ones(p)\n",
    "\n",
    "    idx_order = np.arange(p)\n",
    "    num_active = p\n",
    "\n",
    "    selected_enough = False\n",
    "    num_selected = 0\n",
    "\n",
    "    while not selected_enough:\n",
    "\n",
    "        # subset to acvice variables\n",
    "        Sigma_R_active = Sigma_R[:num_active, :num_active]\n",
    "\n",
    "        if num_selected < len(include):\n",
    "            j_star = np.where(idx_order == include[num_selected])[0][0]\n",
    "\n",
    "            # If the include variables are colinear return a colinearity error\n",
    "            if j_star > num_active - 1:\n",
    "                warnings.warn(\"Variables \" + str(include[:num_selected + 1]) + \" that have been requested to be included are colinear.\")\n",
    "                S[num_selected] = idx_order[j_star]\n",
    "                num_selected += 1\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            # compute objective values\n",
    "            obj_vals = css_score(Sigma_R_active, tol=tol)\n",
    "\n",
    "            # set the exclude objective values to infinity\n",
    "            obj_vals[np.in1d(idx_order[:num_active], exclude)] = np.inf\n",
    "            # select next variable\n",
    "            j_star = random_argmin(obj_vals)\n",
    "\n",
    "        S[num_selected] = idx_order[j_star]\n",
    "        num_selected += 1\n",
    "\n",
    "        # regress off selected variable\n",
    "        regress_one_off_in_place(Sigma_R_active, j_star, tol=tol)\n",
    "\n",
    "        # swap selected variable with last active position\n",
    "        swap_in_place(Sigma_R, [j_star], [num_active - 1], idx_order=idx_order)\n",
    "        # decrement number active\n",
    "        num_active -= 1\n",
    "\n",
    "        # swap any variables with < tol variance to bottom and update num active\n",
    "        zero_idxs = np.where(np.diag(Sigma_R_active)[:num_active] < tol)[0]\n",
    "        num_zero_idxs = len(zero_idxs)\n",
    "        idxs_to_swap = np.arange(num_active - num_zero_idxs, num_active)\n",
    "        swap_in_place(Sigma_R, zero_idxs, idxs_to_swap, idx_order=idx_order)\n",
    "        num_active -= num_zero_idxs\n",
    "\n",
    "        # continue if not enough included\n",
    "        if num_selected < len(include):\n",
    "            continue\n",
    "        # terminate early if all variables are explained\n",
    "        if set(idx_order[:num_active]).issubset(exclude):\n",
    "            selected_enough = True\n",
    "        # terminate if user requested k and k have been selected\n",
    "        if k is not None and num_selected == k:\n",
    "            selected_enough = True\n",
    "        # terminate if below user's cutoff\n",
    "        if cutoffs is not None and np.trace(Sigma_R) <= cutoffs[num_selected - 1]:\n",
    "            selected_enough = True\n",
    "\n",
    "    perm_in_place(Sigma_R, np.arange(p), np.argsort(idx_order))\n",
    "\n",
    "    return S[:num_selected], Sigma_R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "efb78979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_factor_score(Sigma_R, tol=TOL):\n",
    "\n",
    "    diag = np.diag(Sigma_R)\n",
    "    resids = diag - (1/diag)[:, None] * np.square(Sigma_R)\n",
    "    np.fill_diagonal(resids, 1)\n",
    "\n",
    "    if np.any(resids < tol):\n",
    "        return None, np.where(resids < tol)\n",
    "    else:\n",
    "        objective_values = np.log(diag) + np.sum(np.log(resids), axis=1)\n",
    "        return objective_values, (np.array([]), np.array([]))\n",
    "\n",
    "def check_greedy_subset_factor_inputs(Sigma, cutoffs, include, exclude, tol):\n",
    "    n, p = Sigma.shape \n",
    "\n",
    "    if not n == p:\n",
    "        raise ValueError(\"Sigma must be a square matrix.\")\n",
    "  \n",
    "    if not isinstance(cutoffs, (list, np.ndarray)) or not len(cutoffs) == p + 1:\n",
    "        raise ValueError(\"Must provide p + 1 cutoffs.\")\n",
    "\n",
    "    set_include = set(include)\n",
    "    set_exclude = set(exclude)\n",
    "    if not isinstance(include, np.ndarray) or (include.dtype != 'int' and len(include) > 0) or not set_include.issubset(np.arange(p)): \n",
    "        raise ValueError('Include must be a numpy array of integers from 0 to p-1.')\n",
    "    if not isinstance(exclude, np.ndarray) or (exclude.dtype != 'int' and len(exclude) > 0) or not set_exclude.issubset(np.arange(p)):\n",
    "        raise ValueError('Exclude must be a numpy array of integers from 0 to p-1.')\n",
    "    if len(set_exclude.intersection(set_include)) > 0:\n",
    "        raise ValueError(\"Include and exclude must be disjoint.\")\n",
    "\n",
    "    if not isinstance(tol, float):\n",
    "        raise ValueError(\"tol must be a float.\")\n",
    "\n",
    "    return\n",
    "\n",
    "def greedy_subset_factor_selection(Sigma,\n",
    "                                   cutoffs,\n",
    "                                   include=np.array([]),\n",
    "                                   exclude=np.array([]),\n",
    "                                   tol=TOL,\n",
    "                                   ):\n",
    "\n",
    "    check_greedy_subset_factor_inputs(Sigma, cutoffs, include, exclude, tol)\n",
    "    \n",
    "    Sigma_R = Sigma.copy()\n",
    "    p = Sigma.shape[0]\n",
    "    \n",
    "    # check if size-0 subset is sufficient \n",
    "    reject = np.sum(np.log(np.diag(Sigma_R))) > cutoffs[0]\n",
    "    if (not reject and len(include) == 0) or len(exclude) == p:\n",
    "        return np.array([]), reject\n",
    "        \n",
    "    \n",
    "    S = -1 * np.ones(p).astype(int)\n",
    "    idx_order = np.arange(p)\n",
    "    num_active = p\n",
    "\n",
    "    selected_enough = False\n",
    "    num_selected = 0\n",
    "\n",
    "    running_residuals = -1 * np.ones(p)\n",
    "\n",
    "    # subset to acvice variables\n",
    "    Sigma_R_active = Sigma_R[:num_active, :num_active]\n",
    "    while not selected_enough:\n",
    "\n",
    "        if num_selected < len(include):\n",
    "            j_star = np.where(idx_order == include[num_selected])[0][0]\n",
    "        else:\n",
    "            # compute objective values\n",
    "            obj_vals, colinearity_errors = subset_factor_score(Sigma_R_active, tol=tol)\n",
    "\n",
    "            # if adding a variable results in zero residual, warn the user and fail to reject\n",
    "            if len(colinearity_errors[0]) > 0:\n",
    "                warnings.warn(\"When you add variable \"  + str(colinearity_errors[0]) + \" to \" + str(S[:num_selected]) + \" it perfectly explains variable \" + str(colinearity_errors[1]) + \".\")\n",
    "                reject = False\n",
    "                return np.concatenate([S[:num_selected], np.array(colinearity_errors[0][1])]), reject\n",
    "\n",
    "            # set the exclude objective values to infinity\n",
    "            obj_vals[np.in1d(idx_order[:num_active], exclude)] = np.inf\n",
    "            # select next variable\n",
    "            j_star = random_argmin(obj_vals)\n",
    "\n",
    "        S[num_selected] = idx_order[j_star]\n",
    "        running_residuals[num_selected] = Sigma_R_active[j_star, j_star]\n",
    "        num_selected += 1\n",
    "\n",
    "        # regress off selected variable\n",
    "        regress_one_off_in_place(Sigma_R_active, j_star, tol=tol)\n",
    "\n",
    "        # swap selected variable with last active position\n",
    "        swap_in_place(Sigma_R, [j_star], [num_active - 1], idx_order=idx_order)\n",
    "        # decrement number active\n",
    "        num_active -= 1\n",
    "\n",
    "        # subset_to_active_variables\n",
    "        Sigma_R_active = Sigma_R[:num_active, :num_active]\n",
    "\n",
    "        # when including variables that have been requested to be included, ensure that no residuals are zero\n",
    "        if num_selected <= len(include):\n",
    "            zeros = np.where(np.diag(Sigma_R_active) < tol)[0]\n",
    "            if len(zeros) > 0:\n",
    "                warnings.warn(\"Variables \" + str(S[:num_selected]) + \" perfectly explain \" + str(idx_order[zeros]) + \".\")\n",
    "                reject = False\n",
    "                return include, reject\n",
    "\n",
    "        # continue if not enough included\n",
    "        if num_selected < len(include):\n",
    "            continue\n",
    "\n",
    "        # if we fail to reject, terminate and return\n",
    "        if np.sum(np.log(np.diag(Sigma_R_active))) + np.sum(np.log(running_residuals[:num_selected])) <= cutoffs[num_selected]:\n",
    "            reject = False\n",
    "            selected_enough = True\n",
    "\n",
    "        # forcefully fail to reject once we've selected at least p-1 in case of numerical instability\n",
    "        if num_selected >= p - 1:\n",
    "            reject = False\n",
    "            selected_enough = True\n",
    "\n",
    "        # terminate if no variables are left to select\n",
    "        if set(idx_order[:num_active]).issubset(exclude):\n",
    "            selected_enough = True\n",
    "\n",
    "    return S[:num_selected], reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "348418aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_swapping_css_inputs(Sigma,\n",
    "                              k,\n",
    "                              max_iter,\n",
    "                              num_inits, \n",
    "                              S_init,\n",
    "                              include,\n",
    "                              exclude,\n",
    "                              tol):\n",
    "    n, p = Sigma.shape \n",
    "\n",
    "    if not n == p:\n",
    "        raise ValueError(\"Sigma must be a square matrix.\")\n",
    "\n",
    "    if not isinstance(k, (int, np.integer)) or k <= 0 or k > p:\n",
    "        raise ValueError(\"k must be an integer > 0 and <= p.\")\n",
    "    \n",
    "    if S_init is not None:\n",
    "        if not isinstance(S_init, np.ndarray) or  len(set(S_init)) != k or (not set(S_init).issubset(np.arange(p))):\n",
    "            raise ValueError(\"S_init must be a numpy array of length k containing indices 0 to p-1.\")\n",
    "        if not set(include).issubset(S_init):\n",
    "            raise ValueError(\"Include must be a subset of S_init.\")\n",
    "        if len(set(exclude).intersection(S_init)) > 0:\n",
    "            raise ValueError(\"S_init cannot contain any elements in exlcude.\")\n",
    "        \n",
    "    set_include = set(include)\n",
    "    set_exclude = set(exclude)\n",
    "    if not set_include.issubset(np.arange(p)):\n",
    "        raise ValueError(\"Exclude must be a subset of the available indices.\")\n",
    "    if not set_exclude.issubset(np.arange(p)):\n",
    "        raise ValueError(\"Include must be a subset of the available indices.\")\n",
    "    if len(set_exclude.intersection(set_include)) > 0:\n",
    "        raise ValueError(\"Include and exclude must be disjoint.\")\n",
    "\n",
    "    if len(include) > k:\n",
    "        raise ValueError(\"Cannot include more than k.\")\n",
    "    if k is not None and len(exclude) > p - k:\n",
    "        raise ValueError(\"Cannot exclude more than p-k.\")\n",
    "\n",
    "\n",
    "    if not isinstance(tol, float):\n",
    "        raise ValueError(\"tol must be a float.\")\n",
    "\n",
    "def swapping_css_with_init(Sigma,\n",
    "                           S_init,\n",
    "                           max_iter,\n",
    "                           include,\n",
    "                           exclude,\n",
    "                           tol=TOL):\n",
    "    k = len(S_init)\n",
    "    p = Sigma.shape[0]\n",
    "    d = p-k\n",
    "    include_set = set(include)\n",
    "\n",
    "    idx_order = np.arange(p)\n",
    "\n",
    "    Sigma_R = Sigma.copy()\n",
    "    # these will always be the indices of the selected subset\n",
    "    subset_idxs = np.arange(d, p)\n",
    "    # swap initial variables to bottom of Sigma\n",
    "    swap_in_place(Sigma_R, subset_idxs, S_init, idx_order=idx_order)\n",
    "    S = idx_order[d:].copy()\n",
    "    Sigma_S = Sigma[:, S][S, :].copy()\n",
    "    invertible, Sigma_S_L = is_invertible(Sigma_S)   \n",
    "\n",
    "    if not invertible:\n",
    "        return None, None, None \n",
    "\n",
    "    regress_off_in_place(Sigma_R, np.arange(d, p))\n",
    "\n",
    "    # number of completed iterations\n",
    "    N = 0\n",
    "    # counter of how many consecutive times we have chose not to swap \n",
    "    not_replaced = 0\n",
    "    # permutation which shifts the last variable in the subset to the top of the subset\n",
    "    subset_idxs_permuted = np.concatenate([subset_idxs[1:], np.array([subset_idxs[0]])])\n",
    "    converged = False\n",
    "\n",
    "    while N < max_iter and (not converged):\n",
    "        for i in range(k):\n",
    "            S_0 = S[0]\n",
    "\n",
    "            # Update cholesky after removing first variable from subset\n",
    "            Sigma_T_L = update_cholesky_after_removing_first(Sigma_S_L)\n",
    "\n",
    "            if S_0 not in include_set:\n",
    "            \n",
    "                # Subest with first variable removed  from selected subset\n",
    "                T = S[1:]\n",
    "\n",
    "                # Update residual covariance after removing first variable from subset\n",
    "                v = Sigma[:, S_0] - Sigma[:, T] @ solve_with_cholesky(Sigma_T_L, Sigma[T, S_0]) if k > 1 else Sigma[:, S_0]\n",
    "                reordered_v = v[idx_order]\n",
    "                Sigma_R = Sigma_R + np.outer(reordered_v, reordered_v)/v[S_0]\n",
    "                \n",
    "                # Swap first variable from subset to to top of residual matrix\n",
    "                swap_in_place(Sigma_R, np.array([0]), np.array([d]), idx_order=idx_order)\n",
    "\n",
    "                # find indices of variables with zero variance\n",
    "                zero_idxs = np.where(np.diag(Sigma_R)[:(d + 1)] <= tol)[0]\n",
    "                num_zero_idxs = len(zero_idxs)\n",
    "                # In residual matrix, swap variables with zero indices to right above currently selected subset (of size k-1)\n",
    "                swap_in_place(Sigma_R, zero_idxs, np.arange(d + 1 - num_zero_idxs, d + 1), idx_order=idx_order)\n",
    "                \n",
    "                # update num_active\n",
    "                num_active = d + 1 - num_zero_idxs\n",
    "\n",
    "                # compute objectives and for active variables and find minimizers\n",
    "                obj_vals = css_score(Sigma_R[:num_active, :num_active], tol=tol)\n",
    "\n",
    "                # set the objective value to infinity for the excluded variables\n",
    "                obj_vals[np.in1d(idx_order[:num_active], exclude)] = np.inf\n",
    "\n",
    "                choices = np.flatnonzero(obj_vals == obj_vals.min())\n",
    "\n",
    "                # if removed variable is a choice, select it, otherwise select a random choice\n",
    "                if 0 in choices:\n",
    "                    not_replaced += 1\n",
    "                    j_star = 0\n",
    "                else:\n",
    "                    not_replaced = 0\n",
    "                    j_star = np.random.choice(choices)\n",
    "                \n",
    "                S_new = idx_order[j_star]\n",
    "                \n",
    "                # In residual covariance, regress selected variable off the remaining\n",
    "                #regress_one_off_in_place(Sigma_R[:(d+1), :(d+1)], j_star) #alternative option\n",
    "                regress_one_off_in_place(Sigma_R[:num_active, :num_active], j_star)\n",
    "                # In residual covariance swap new choice to top of selected subset \n",
    "                swap_in_place(Sigma_R, np.array([j_star]), np.array([d]), idx_order=idx_order)\n",
    "              \n",
    "            else:\n",
    "                S_new = S_0 \n",
    "            \n",
    "            # Add new choice as the last variable in selected subset\n",
    "            S[:k-1] = S[1:]\n",
    "            S[k-1] = S_new\n",
    "            # Update cholesky after adding new choice as last variable in selected subset\n",
    "            Sigma_S_L = update_cholesky_after_adding_last(Sigma_T_L, Sigma[S_new, S])\n",
    "            \n",
    "            # permute first variables in selected subset to the last variable in the residual matrix\n",
    "            perm_in_place(Sigma_R, subset_idxs,  subset_idxs_permuted, idx_order=idx_order)\n",
    "\n",
    "            if not_replaced == k - len(include):\n",
    "                converged=True\n",
    "                break\n",
    "\n",
    "        N += 1\n",
    "\n",
    "    perm_in_place(Sigma_R, np.arange(p), np.argsort(idx_order))\n",
    "    \n",
    "    return S, Sigma_R, converged \n",
    "\n",
    "def swapping_css(Sigma,\n",
    "                 k,\n",
    "                 max_iter=100,\n",
    "                 num_inits=1, \n",
    "                 S_init=None,\n",
    "                 include=np.array([]),\n",
    "                 exclude=np.array([]),\n",
    "                 tol=TOL):\n",
    "\n",
    "    check_swapping_css_inputs(Sigma,\n",
    "                              k,\n",
    "                              max_iter,\n",
    "                              num_inits, \n",
    "                              S_init,\n",
    "                              include,\n",
    "                              exclude,\n",
    "                              tol)\n",
    "    \n",
    "    best_converged = None\n",
    "    best_S = None\n",
    "    best_S_init = None \n",
    "    best_Sigma_R = None\n",
    "    best_obj_val = np.inf \n",
    "    not_include = np.array([idx for idx in complement(Sigma.shape[0], include) if idx not in set(exclude)])\n",
    "    \n",
    "    if len(include) > 0:\n",
    "        invertible, _ = is_invertible(Sigma[include, :][:, include], tol=tol)\n",
    "        if not invertible:\n",
    "            warnings.warn(\"The variables requested to be included are colinear.\")\n",
    "            return best_S, best_Sigma_R, best_S_init, best_converged   \n",
    "    \n",
    "    no_initialization = (S_init is None)\n",
    "    if not no_initialization:\n",
    "        num_inits = 1\n",
    "\n",
    "    for _ in range(num_inits):\n",
    "        if no_initialization:\n",
    "            S_init = np.concatenate([include, np.random.choice(not_include, k-len(include), replace=False)]).astype(int)\n",
    "\n",
    "        S, Sigma_R, converged  = swapping_css_with_init(Sigma=Sigma,\n",
    "                                                        S_init=S_init,\n",
    "                                                        max_iter=max_iter, \n",
    "                                                        include=include,\n",
    "                                                        exclude=exclude,\n",
    "                                                        tol=TOL)\n",
    "        if S is None:\n",
    "            continue \n",
    "      \n",
    "        obj_val = np.trace(Sigma_R)\n",
    "        if obj_val < best_obj_val:\n",
    "            best_obj_val = obj_val \n",
    "            best_S = S\n",
    "            best_S_init = S_init\n",
    "            best_Sigma_R = Sigma_R\n",
    "            best_converged = converged \n",
    "\n",
    "    if best_S is None:\n",
    "        warnings.warn(\"All the initializations tried were colinear.\")\n",
    "    return best_S, best_Sigma_R, best_S_init, best_converged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e7600fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_swapping_subest_factor_inputs(Sigma,\n",
    "                                        k,\n",
    "                                        cutoff, \n",
    "                                        max_iter,\n",
    "                                        num_inits, \n",
    "                                        S_init,\n",
    "                                        find_minimizer,\n",
    "                                        include,\n",
    "                                        exclude,\n",
    "                                        tol):\n",
    "    n, p = Sigma.shape \n",
    "\n",
    "    if not n == p:\n",
    "        raise ValueError(\"Sigma must be a square matrix.\")\n",
    "\n",
    "    if not isinstance(k, (int, np.integer)) or k < 0 or k > p:\n",
    "        raise ValueError(\"k must be an integer between 0 and p (inclusive).\")\n",
    "    \n",
    "    set_include = set(include)\n",
    "    set_exclude = set(exclude)\n",
    "    if not isinstance(include, np.ndarray) or (include.dtype != 'int' and len(include) > 0) or not set_include.issubset(np.arange(p)): \n",
    "        raise ValueError('Include must be a numpy array of integers from 0 to p-1.')\n",
    "    if not isinstance(exclude, np.ndarray) or (exclude.dtype != 'int' and len(exclude) > 0) or not set_exclude.issubset(np.arange(p)):\n",
    "        raise ValueError('Exclude must be a numpy array of integers from 0 to p-1.')\n",
    "    if len(set_exclude.intersection(set_include)) > 0:\n",
    "        raise ValueError(\"Include and exclude must be disjoint.\")\n",
    "    \n",
    "    if S_init is not None:\n",
    "        if not isinstance(S_init, np.ndarray) or S_init.dtype != 'int' or len(set(S_init)) != k or (not set(S_init).issubset(np.arange(p))):\n",
    "            raise ValueError(\"S_init must be a numpy array of k integers from 0 to p-1 inclusive.\")\n",
    "        if not set(include).issubset(S_init):\n",
    "            raise ValueError(\"Include must be a subset of S_init.\")\n",
    "        if len(set(exclude).intersection(S_init)) > 0:\n",
    "            raise ValueError(\"S_init cannot contain any elements in exlcude.\")\n",
    "        \n",
    "\n",
    "    if len(include) > k:\n",
    "        raise ValueError(\"Cannot include more than k.\")\n",
    "    if k is not None and len(exclude) > p - k:\n",
    "        raise ValueError(\"Cannot exclude more than p-k.\")\n",
    "\n",
    "\n",
    "    if not isinstance(tol, float):\n",
    "        raise ValueError(\"tol must be a float.\")\n",
    "    \n",
    "    return \n",
    "\n",
    "def swapping_subset_factor_with_init(Sigma, \n",
    "                                     S_init,\n",
    "                                     find_minimizer,\n",
    "                                     cutoff, \n",
    "                                     max_iter,\n",
    "                                     include,\n",
    "                                     exclude,\n",
    "                                     tol=TOL):\n",
    "    \n",
    "    \n",
    "    k = len(S_init)\n",
    "    \n",
    "    # handle case where subset must be empty \n",
    "    if k == 0:\n",
    "        log_det = np.sum(np.log(np.diag(Sigma)))\n",
    "        reject = log_det > cutoff\n",
    "        return np.array([]), reject, log_det \n",
    "    \n",
    "    p = Sigma.shape[0]\n",
    "    d = p-k\n",
    "    include_set = set(include)\n",
    "\n",
    "    idx_order = np.arange(p)\n",
    "\n",
    "    Sigma_R = Sigma.copy()\n",
    "    # these will always be the indices of the selected subset\n",
    "    subset_idxs = np.arange(d, p)\n",
    "    # swap initial variables to bottom of Sigma\n",
    "    swap_in_place(Sigma_R, subset_idxs, S_init, idx_order=idx_order)\n",
    "    S = idx_order[d:].copy()\n",
    "    Sigma_S = Sigma[:, S][S, :].copy()\n",
    "    invertible, Sigma_S_L = is_invertible(Sigma_S)   \n",
    "\n",
    "    if not invertible:\n",
    "        warnings.warn(\"Variables \" + str(S_init) + \" are colinear.\" )\n",
    "        reject = False\n",
    "        return S_init, reject, -np.inf  \n",
    "\n",
    "    regress_off_in_place(Sigma_R, np.arange(d, p))\n",
    "    \n",
    "    where_zeros = np.where(np.diag(Sigma_R)[:d] < tol)[0]\n",
    "    if len(where_zeros > 0):\n",
    "        warnings.warn(\"Variables \" + str(S_init) + \" perfectly explain \" + str(idx_order[where_zeros]) )\n",
    "        reject = False \n",
    "        return S_init, reject, -np.inf \n",
    "    \n",
    "\n",
    "    # number of completed iterations\n",
    "    N = 0\n",
    "    # counter of how many consecutive times we have chose not to swap \n",
    "    not_replaced = 0\n",
    "    # permutation which shifts the last variable in the subset to the top of the subset\n",
    "    subset_idxs_permuted = np.concatenate([subset_idxs[1:], np.array([subset_idxs[0]])])\n",
    "    converged = False\n",
    "\n",
    "    while N < max_iter and (not converged):\n",
    "        for i in range(k):\n",
    "            S_0 = S[0]\n",
    "\n",
    "            # Update cholesky after removing first variable from subset\n",
    "            Sigma_T_L = update_cholesky_after_removing_first(Sigma_S_L)\n",
    "\n",
    "            if S_0 not in include_set:\n",
    "            \n",
    "                # Subest with first variable removed from selected subset\n",
    "                T = S[1:]\n",
    "\n",
    "                # Update residual covariance after removing first variable from subset\n",
    "                v = Sigma[:, S_0] - Sigma[:, T] @ solve_with_cholesky(Sigma_T_L, Sigma[T, S_0]) if k > 1 else Sigma[:, S_0]\n",
    "                reordered_v = v[idx_order]\n",
    "                Sigma_R = Sigma_R + np.outer(reordered_v, reordered_v)/v[S_0]\n",
    "                \n",
    "                # Swap first variable from subset to to top of residual matrix\n",
    "                swap_in_place(Sigma_R, np.array([0]), np.array([d]), idx_order=idx_order)\n",
    "                \n",
    "                # compute objectives and for active variables and find minimizers\n",
    "                obj_vals, colinearity_errors = subset_factor_score(Sigma_R[:(d+1), :(d+1)], tol=tol)\n",
    "\n",
    "                # if adding a variable results in zero residual, warn the user and fail to reject\n",
    "                if len(colinearity_errors[0]) > 0:\n",
    "                    warnings.warn(\"When you add variable \"  + str(colinearity_errors[0]) + \" to \" + str(S[:num_selected]) + \" it perfectly explains variable \" + str(colinearity_errors[1]) + \".\")\n",
    "                    reject = False\n",
    "                    return np.concatenate([T, np.array(colinearity_errors[0][1])]), reject, -np.inf\n",
    "\n",
    "                # set the objective value to infinity for the excluded variables\n",
    "                obj_vals[np.in1d(idx_order[:(d+1)], exclude)] = np.inf\n",
    "\n",
    "                choices = np.flatnonzero(obj_vals == obj_vals.min())\n",
    "\n",
    "                # if removed variable is a choice, select it, otherwise select a random choice\n",
    "                if 0 in choices:\n",
    "                    not_replaced += 1\n",
    "                    j_star = 0\n",
    "                else:\n",
    "                    not_replaced = 0\n",
    "                    j_star = np.random.choice(choices)\n",
    "                \n",
    "                S_new = idx_order[j_star]\n",
    "                \n",
    "                # In residual covariance, regress selected variable off the remaining\n",
    "                regress_one_off_in_place(Sigma_R[:(d+1), :(d+1)], j_star)\n",
    "                # In residual covariance swap new choice to top of selected subset \n",
    "                swap_in_place(Sigma_R, np.array([j_star]), np.array([d]), idx_order=idx_order)\n",
    "              \n",
    "            else:\n",
    "                S_new = S_0 \n",
    "            \n",
    "            # Add new choice as the last variable in selected subset\n",
    "            S[:k-1] = S[1:]\n",
    "            S[k-1] = S_new\n",
    "            # Update cholesky after adding new choice as last variable in selected subset\n",
    "            Sigma_S_L = update_cholesky_after_adding_last(Sigma_T_L, Sigma[S_new, S])\n",
    "            \n",
    "            # permute first variables in selected subset to the last variable in the residual matrix\n",
    "            perm_in_place(Sigma_R, subset_idxs,  subset_idxs_permuted, idx_order=idx_order)\n",
    "            \n",
    "            # If you don't want to find the minimizer and log det is small enough, terminate now\n",
    "            if not find_minimizer:\n",
    "                log_det = np.sum(np.log(np.diag(Sigma_R)[:d])) + np.sum(np.log(np.square(np.diag(Sigma_S_L))))\n",
    "                if log_det <= cutoff:\n",
    "                    reject = False\n",
    "                    return S, reject, log_det\n",
    "\n",
    "            if not_replaced == k - len(include):\n",
    "                converged=True\n",
    "                break\n",
    "\n",
    "        N += 1\n",
    "\n",
    "    log_det = np.sum(np.log(np.diag(Sigma_R)[:d])) + np.sum(np.log(np.square(np.diag(Sigma_S_L))))\n",
    "    reject = (log_det > cutoff)\n",
    "    return S, reject, log_det\n",
    "\n",
    "def swapping_subset_factor_selection(Sigma,\n",
    "                                     k,\n",
    "                                     cutoff,\n",
    "                                     max_iter=100,\n",
    "                                     num_inits=1, \n",
    "                                     S_init=None,\n",
    "                                     find_minimizer=False, \n",
    "                                     include=np.array([]),\n",
    "                                     exclude=np.array([]),\n",
    "                                     tol=TOL):\n",
    "    \n",
    "    check_swapping_subest_factor_inputs(Sigma,\n",
    "                                        k,\n",
    "                                        cutoff, \n",
    "                                        max_iter,\n",
    "                                        num_inits, \n",
    "                                        S_init,\n",
    "                                        find_minimizer,\n",
    "                                        include,\n",
    "                                        exclude,\n",
    "                                        tol)\n",
    "    \n",
    "    reject = True\n",
    "    best_S = None\n",
    "    best_log_det = np.inf \n",
    "    not_include = np.array([idx for idx in complement(Sigma.shape[0], include) if idx not in set(exclude)])\n",
    "    \n",
    "    if len(include) > 0:\n",
    "        invertible, _ = is_invertible(Sigma[include, :][:, include], tol=tol)\n",
    "        if not invertible:\n",
    "            warnings.warn(\"The variables that have been requested to be included are colinear.\")\n",
    "            reject = False\n",
    "            return np.concatenate([include, not_include[:(k - len(incude))]]), reject\n",
    "    \n",
    "    no_initialization = (S_init is None)\n",
    "    if not no_initialization or k == 0 or k == 1:\n",
    "        num_inits = 1\n",
    "\n",
    "    for _ in range(num_inits):\n",
    "        if no_initialization:\n",
    "            S_init = np.concatenate([include, np.random.choice(not_include, k-len(include), replace=False)]).astype(int)\n",
    "\n",
    "        S, reject, log_det = swapping_subset_factor_with_init(Sigma=Sigma,\n",
    "                                                              S_init=S_init,\n",
    "                                                              find_minimizer=find_minimizer,\n",
    "                                                              cutoff=cutoff,\n",
    "                                                              max_iter=max_iter, \n",
    "                                                              include=include,\n",
    "                                                              exclude=exclude,\n",
    "                                                              tol=TOL)\n",
    "        if not find_minimizer and (not reject):\n",
    "            return S, reject \n",
    "        \n",
    "        if find_minimizer and (not reject):\n",
    "            reject = reject\n",
    "\n",
    "        if log_det < best_log_det:\n",
    "            best_S = S\n",
    "            best_log_det = log_det \n",
    "\n",
    "    return best_S, reject "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "87ec7702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_null_dist(n, p, k, B=int(1e5), seed=0):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(0)\n",
    "\n",
    "    num_adjusted_samples = n - k - 1\n",
    "    num_features = p-k\n",
    "    full_dfs = np.array([num_adjusted_samples - i + 1 for i in range(1, num_features + 1)])\n",
    "    full_chi_sqs = np.random.chisquare(df=full_dfs, size=(B, len(full_dfs)))\n",
    "\n",
    "    null_dfs = np.arange(1, num_features)\n",
    "    null_chi_sqs = np.random.chisquare(df=null_dfs, size=(B, len(null_dfs)))\n",
    "    null_chi_sqs = np.hstack([np.zeros(B).reshape((B, 1)), null_chi_sqs])\n",
    "    return n*(np.sum( np.log(null_chi_sqs/full_chi_sqs + 1), axis=1))\n",
    "\n",
    "def Q(qs, n, p, k, B=int(1e5), seed=0):\n",
    "\n",
    "    return np.quantile(sample_null_dist(n, p, k, B=B, seed=seed), qs)\n",
    "\n",
    "def subset_selection(X, \n",
    "                     alpha, \n",
    "                     include=np.array([]), \n",
    "                     exclude=np.array([]), \n",
    "                     quantile_dict={}, \n",
    "                     B=int(1e5),\n",
    "                     max_iter=100,\n",
    "                     num_inits=1,\n",
    "                     tol=TOL):\n",
    "    n, p = X.shape\n",
    "    _, Sigma_hat = get_moments(X)\n",
    "    Sigma_hat = standardize_cov(Sigma_hat)\n",
    "    \n",
    "    crit_vals = np.array([Q(1-alpha, n, p, i, B=B) if (1 - alpha, n, p , i) not in quantile_dict.keys() else quantile_dict[( 1 - alpha, n, p , i)] for i in range(p + 1)])\n",
    "    cutoffs = crit_vals/n  + np.linalg.slogdet(Sigma_hat)[1]\n",
    "\n",
    "    S, reject = greedy_subset_factor_selection(Sigma_hat,\n",
    "                                               cutoffs,\n",
    "                                               include=include,\n",
    "                                               exclude=exclude,\n",
    "                                               tol=tol)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if reject:\n",
    "        warnings.warn(\"We can still reject the model with this S, but nothing more can be added.\")\n",
    "        return S\n",
    "    if len(S) <= 1:\n",
    "        return S \n",
    "\n",
    "\n",
    "    k = len(S)\n",
    "    while not reject:\n",
    "        k = k-1\n",
    "        S, reject = swapping_subset_factor_selection(Sigma_hat,\n",
    "                                                     k,\n",
    "                                                     cutoffs[k],\n",
    "                                                     max_iter=max_iter,\n",
    "                                                     num_inits=num_inits,\n",
    "                                                     include=include,\n",
    "                                                     exclude=exclude,\n",
    "                                                     tol=TOL)\n",
    "        if reject:\n",
    "            S, reject = swapping_subset_factor_selection(Sigma_hat,\n",
    "                                                         k+1,\n",
    "                                                         cutoffs[k+1],\n",
    "                                                         max_iter=max_iter,\n",
    "                                                         num_inits=num_inits,\n",
    "                                                         find_minimizer=True,\n",
    "                                                         include=include,\n",
    "                                                         exclude=exclude,\n",
    "                                                         tol=TOL)\n",
    "            return S \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "05dddb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_csv(\"../data/BFI228.csv\").values[:, 1:].astype(int)\n",
    "n, p = X.shape\n",
    "_, Sigma_hat = get_moments(X)\n",
    "\n",
    "alpha = 0.1\n",
    "quantile_dict = {(1 - alpha, n, p, i,):  Q(1 -alpha, n, p, i,) for i in range(p + 1) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "e08feff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01699209213256836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/8gtczpzd5_n_zlbsv10125gw0000gn/T/ipykernel_20754/1391309035.py:45: UserWarning: We can still reject the model with this S, but nothing more can be added.\n",
      "  warnings.warn(\"We can still reject the model with this S, but nothing more can be added.\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "S = subset_selection(X, \n",
    "                 alpha=alpha,  \n",
    "                 quantile_dict=quantile_dict, \n",
    "                 num_inits=1,\n",
    "                 exclude = np.arange(p))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "102d8736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 25, 27, 29, 31, 34, 37, 38, 41, 43])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "0bd2c577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2, 31, 35,  3, 29, 43,  6, 19, 13, 15, 23, 20, 27, 12, 32, 22,\n",
       "       38, 25,  0, 41, 24])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "4fe56821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "42569f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  6  7 12 13 14 15 17 20 22 24 25 27 29 30 35 38 41 43]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "k=20\n",
    "S, reject = swapping_subset_factor_selection(Sigma_hat,\n",
    "                                 k,\n",
    "                                 cutoffs[k-1],\n",
    "                                 max_iter=100,\n",
    "                                 num_inits=100,  \n",
    "                                 tol=TOL)\n",
    "\n",
    "print(np.sort(S))\n",
    "print(reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a79509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "66ceb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0]\n",
      " [1 1 0 0 0]\n",
      " [0 0 3 0 0]\n",
      " [0 0 0 4 0]\n",
      " [0 0 0 0 5]]\n"
     ]
    }
   ],
   "source": [
    "Sigma = np.diag(np.array([1, 1,  3, 4, 5]))\n",
    "Sigma[0, 1] = 1\n",
    "Sigma[1, 0] = 1\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e9022b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 0, 4]),\n",
       " array([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 3., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]),\n",
       " array([0, 3, 2]),\n",
       " True)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapping_css(Sigma,\n",
    "           k=3,\n",
    "           max_iter=100,\n",
    "           num_inits=5, \n",
    "           include=np.array([0]),\n",
    "           exclude=np.array([]),\n",
    "           tol=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "5bf7f4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 4, 2]),\n",
       " array([[1., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]),\n",
       " array([4, 0, 3]),\n",
       " True)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapping_css(Sigma,\n",
    "           k=3,\n",
    "           max_iter=100,\n",
    "           num_inits=1, \n",
    "           include=np.array([]),\n",
    "           exclude=np.array([]),\n",
    "           tol=TOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c3b787",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idxs1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m idxs1, idxs2\u001b[38;5;241m=\u001b[39m [idx \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[43midxs1\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m idxs2], [idx \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs2 \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m idxs1]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idxs1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "958b8841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 9, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma = np.diag(np.eye(10))\n",
    "idx_order = np.array(np.arange(10))\n",
    "swap_in_place(Sigma, np.array([8, 9]), np.array([9, 8]), idx_order=idx_order)\n",
    "idx_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318aaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "3410, 1034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma[0, 0] = 1\n",
    "Sigma[1, 1] = 1\n",
    "Sigma[:2, 2:] = rho\n",
    "Sigma[2:, :2] = rho \n",
    "    Sigma[2:, 2:] = np.diag(np.ones(p-2)) + Sigma[2:, 0] @ Sigma[0, 2:]\n",
    "\n",
    "    S, reject = swapping_subset_factor_selection(Sigma, k=2, S_init=np.array([0, 1]), cutoff=0, tol=TOL)\n",
    "    assert(reject == False)\n",
    "    assert(set(S) == set(np.array([0, 1])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be84ddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({5}, dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(set([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6afafe27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((7, 7))[np.array([4]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1953df37",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs1 = np.array([2, 4])\n",
    "idxs2 = np.array([4, 3])\n",
    "\n",
    "union = set(idxs1).union(set(idxs2))\n",
    "\n",
    "orig = np.concatenate([idxs1, list(set(union) - set(idxs1)) ])\n",
    "perm = np.concatenate([idxs2, list(set(union) - set(idxs2)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1550b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = np.diag(np.array([1, 2, 3, 4, 5]))\n",
    "    \n",
    "S, Sigma_R = greedy_css(Sigma,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "560aec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "True\n",
      "[3 5]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "eps=0.05\n",
    "p=6\n",
    "Sigma = np.diag(np.ones(p))\n",
    "Sigma[2, 0], Sigma[0, 2], Sigma[2, 1], Sigma[1, 2] = 1-eps, 1-eps, 1-eps, 1-eps\n",
    "Sigma[5, 3], Sigma[3, 5], Sigma[5, 4], Sigma[4, 5] = 1-eps, 1-eps, 1-eps, 1-eps\n",
    "S_init = np.array([0, 1])\n",
    "S, _, _, converged = swapping_css(Sigma, k=2, S_init=S_init)\n",
    "print(S)\n",
    "print(converged)\n",
    "S_init = np.array([4, 3])\n",
    "S, _, _, converged = swapping_css(Sigma, k=2, S_init=S_init)\n",
    "print(S)\n",
    "print(converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f16e3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.  , 0.95, 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.95, 0.  , 0.  , 0.  ],\n",
       "       [0.95, 0.95, 1.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 1.  , 0.  , 0.95],\n",
       "       [0.  , 0.  , 0.  , 0.  , 1.  , 0.95],\n",
       "       [0.  , 0.  , 0.  , 0.95, 0.95, 1.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
